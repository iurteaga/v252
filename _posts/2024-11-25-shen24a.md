---
title: The Data Addition Dilemma
abstract: In many machine learning for healthcare tasks, standard datasets are constructed
  by amassing data across many, often fundamentally dissimilar, sources. But when
  does adding more data help, and when does it hinder progress on desired model outcomes
  in real-world settings? We identify this situation as the Data Addition Dilemma,
  demonstrating that adding training data in this multi-source scaling context can
  at times result in reduced overall accuracy, uncertain fairness outcomes and reduced
  worst-subgroup performance. We find that this possibly arises from an empirically
  observed trade-off between model performance improvements due to data scaling and
  model deterioration from distribution shift.  We thus establish baseline strategies
  for navigating this dilemma, introducing distribution shift heuristics to guide
  decision-making for which data sources to add in order to yield the expected model
  performance improvements.  We conclude with a discussion of the required considerations
  for data collection and suggestions for studying data composition and scale in the
  age of increasingly larger models.
openreview: s8WSOR8w3n
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shen24a
month: 0
tex_title: The Data Addition Dilemma
cycles: false
bibtex_author: Shen, Judy Hanwen and Raji, Inioluwa Deborah and Chen, Irene Y.
author:
- given: Judy Hanwen
  family: Shen
- given: Inioluwa Deborah
  family: Raji
- given: Irene Y.
  family: Chen
date: 2024-11-25
address:
container-title: Proceedings of the 9th Machine Learning for Healthcare Conference
volume: '252'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 11
  - 25
pdf: https://raw.githubusercontent.com/mlresearch/v252/main/assets/shen24a/shen24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
