---
title: Direct Preference Optimization for Suppressing Hallucinated Prior Exams in
  Radiology Report Generation
abstract: Recent advances in generative vision-language models (VLMs) have exciting
  potential implications for AI in radiology, yet VLMs are also known to produce hallucinations,
  nonsensical text, and other unwanted behaviors that can waste cliniciansâ€™ time and
  cause patient harm. Drawing on recent work on direct preference optimization (DPO),
  we propose a simple method for modifying the behavior of pretrained VLMs performing
  radiology report generation by suppressing unwanted types of generations. We apply
  our method to the prevention of hallucinations of prior exams, addressing a long-established
  problem behavior in models performing chest X-ray report generation. Across our
  experiments, we find that DPO fine-tuning achieves a 3.2-4.8x reduction in lines
  hallucinating prior exams while maintaining model performance on clinical accuracy
  metrics. Our work is, to the best of our knowledge, the first work to apply DPO
  to medical VLMs, providing a data- and compute- efficient way to suppress problem
  behaviors while maintaining overall clinical accuracy.
openreview: kvYYP1LfRq
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: banerjee24a
month: 0
tex_title: Direct Preference Optimization for Suppressing Hallucinated Prior Exams
  in Radiology Report Generation
cycles: false
bibtex_author: Banerjee, Oishi and Zhou, Hong-Yu and Wu, Kay and Adithan, Subathra
  and Kwak, Stephen and Rajpurkar, Pranav
author:
- given: Oishi
  family: Banerjee
- given: Hong-Yu
  family: Zhou
- given: Kay
  family: Wu
- given: Subathra
  family: Adithan
- given: Stephen
  family: Kwak
- given: Pranav
  family: Rajpurkar
date: 2024-11-25
address:
container-title: Proceedings of the 9th Machine Learning for Healthcare Conference
volume: '252'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 11
  - 25
pdf: https://raw.githubusercontent.com/mlresearch/v252/main/assets/banerjee24a/banerjee24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
