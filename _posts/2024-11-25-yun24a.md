---
title: Automatically Extracting Numerical Results from Randomized Controlled Trials
  with Large Language Models
abstract: Meta-analyses statistically aggregate the findings of different randomized
  controlled trials (RCTs) to assess treatment effectiveness. Because this yields
  robust estimates of treatment effectiveness, results from meta-analyses are considered
  the strongest form of evidence. However, rigorous evidence syntheses are time-consuming
  and labor-intensive, requiring manual extraction of data from individual trials
  to be synthesized. Ideally, language technologies would permit fully automatic meta-analysis,
  on demand. This requires accurately extracting numerical results from individual
  trials, which has been beyond the capabilities of natural language processing (NLP)
  models to date. In this work, we evaluate whether modern large language models (LLMs)
  can reliably perform this task. We annotate (and release) a modest but granular
  evaluation dataset of clinical trial reports with numerical findings attached to
  interventions, comparators, and outcomes. Using this dataset, we evaluate the performance
  of seven LLMs applied zero-shot for the task of conditionally extracting numerical
  findings from trial reports. We find that massive LLMs that can accommodate lengthy
  inputs are tantalizingly close to realizing fully automatic meta-analysis, especially
  for dichotomous (binary) outcomes (e.g., mortality). However, LLMs—including ones
  trained on biomedical texts—perform poorly when the outcome measures are complex
  and tallying the results requires inference. This work charts a path toward fully
  automatic meta-analysis of RCTs via LLMs, while also highlighting the limitations
  of existing models for this aim.
openreview: VUiZ69NyST
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yun24a
month: 0
tex_title: Automatically Extracting Numerical Results from Randomized Controlled Trials
  with Large Language Models
cycles: false
bibtex_author: Yun, Hye Sun and Pogrebitskiy, David and Marshall, Iain James and Wallace,
  Byron C
author:
- given: Hye Sun
  family: Yun
- given: David
  family: Pogrebitskiy
- given: Iain James
  family: Marshall
- given: Byron C
  family: Wallace
date: 2024-11-25
address:
container-title: Proceedings of the 9th Machine Learning for Healthcare Conference
volume: '252'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 11
  - 25
pdf: https://raw.githubusercontent.com/mlresearch/v252/main/assets/yun24a/yun24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
